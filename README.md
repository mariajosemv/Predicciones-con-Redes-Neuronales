# üß†üîÄ Predicciones a trav√©s de redes neuronales artificiales

Inspirada en la naturaleza de las redes neuronales de nuestro cerebro, en los siguientes proyectos se realizan predicciones tomando como entrada los datos de inter√©s. El algoritmo implementado en cada proyecto es organizado en diferentes n√∫meros de capas que representan ciertas funciones matem√°ticas. En cada capa se reconocen patrones y caracter√≠sticas que permiten, en √∫ltima instancia, entregar una predicci√≥n con un cierto nivel de confianza. 

Los proyectos son presentados de acuerdo al orden de complejidad de la red neuronal y se ordenan de la siguiente manera:

- 1Ô∏è‚É£ Implementaci√≥n de un perceptr√≥n (red neuronal b√°sica) para un problema de clasificaci√≥n binaria: discernir entre especies de flores.

- 2Ô∏è‚É£ Dise√±o, entrenamiento y evaluaci√≥n de una red neuronal multicapa para un problema de regresi√≥n: predecir precios de viviendas en Boston.

- 3Ô∏è‚É£ Dise√±o, entrenamiento y evaluaci√≥n de una red neuronal multicapa para un problema de clasificaci√≥n: identificar clientes potenciales. 

- 4Ô∏è‚É£ Introducci√≥n al Deep Learning: dise√±o, entrenamiento y evaluaci√≥n de una red neuronal para determinar el precio justo para venta de veh√≠culos usados. 


## üåü Funcionamiento

El algoritmo de una red neuronal funciona de acuerdo los siguientes pasos:

- 1Ô∏è‚É£ Inicializaci√≥n de los pesos sin√°pticos.
- 2Ô∏è‚É£ Definici√≥n de la funci√≥n de activaci√≥n para abstraer relaciones no lineales. 
- 3Ô∏è‚É£ Aplicar funciones de costo para medir la diferencia entre el valor predicho y el valor real.
- 4Ô∏è‚É£ Aplicar el algoritmo de optimizaci√≥n para reducir el error o funci√≥n de costo.
- 5Ô∏è‚É£ Ajustar los pesos sin√°pticos de acuerdo al paso 4.

### üîª Inicializaci√≥n de los pesos

Los rangos de los pesos de inicializaci√≥n que han demostrado ser m√°s efectivos y que son utilizados en este proyecto, est√°n definidos de acuerdo a las variaciones de Glorot/Xavier: 

- Intervalo Uniforme $[-x,x]$:

$$ x = \sqrt{  \frac{6}{E + S} } $$

- Intervalo Normal: con Media 0 y $\sigma$:

$$ \sigma = \sqrt{  \frac{2}{E + S} } $$

donde $E$ y $S$ son la cantidad de entradas y salidas. 

### üîª Funciones de activaci√≥n

Algunas de las funciones m√°s utilizadas son: 

- Funci√≥n Sigmoid o Log√≠stica: Es utilizada especialmente para los modelos en los que tenemos que predecir la probabilidad como un resultado ya que tiene una salida multivalor acotada de (0,1). 

$$ f(x) = \frac{1}{1+e^x}$$ 

- Funci√≥n Tangente Hiperb√≥lica: es usualmente usada en problemas de clasificaci√≥n binaria, con una salida acotada entre (-1,1).

$$ f(x) = \frac{2}{1+e^{2x}} - 1 $$

- ReLU (Rectified Linear Unit): tiene salida no acotada (0,‚àû) y derivadas positivas, por lo que es importante considerar las variables de entrada normalizadas (de 0 a 1). Es usada en problemas de regresi√≥n en los que se entrega una n√∫mero final. 

$$  f(x) =  \begin{cases} 0 & \text{if } x < 0, x & \text{if } x > 0 \end{cases} \} $$


### üîª Funciones de costo

- Para variables num√©ricas: 

    - Mean Absolute Error: de f√°cil interpretaci√≥n y robusta a outliers. 

    $$ MAE = \frac{1}{k} \sum_i^k |Real - Predicho| $$

    - Mean Squared Error: penaliza el modelo cuando existen grandes errores y es sensible a outliers.

    $$ MSE = \frac{1}{k} \sum_i^k (Real - Predicho)^2 $$

    - Mean Absolute Percentage Error: penaliza el modelo cuando existen grandes errores y es robusta a outliers. 
     $$ MAPE = \frac{1}{k} \sum_i^k | \frac{Real - Predicho}{Real}| $$

- Para variables categ√≥ricas:

  - Binary Cross-Entropy: Penaliza el modelo cuando existen grandes errores. En la siguiente ecuaci√≥n, $y_i'$ es el valor predicho y $y_i$ el valor real. 

  $$ H_{y'}(y) := - \sum_{i} ({y_i' \log(y_i) + (1-y_i') \log (1-y_i)}) $$ 

  - Categorical Cross-Entropy: Usada en problemas multiclase, de igual manera penaliza el modelo cuando presenta grandes errores. En la siguiente ecuaci√≥n $p(x)$ es el valor real, y $q(x)$ el valor predicho. 

  $$ H(p,q) = -\sum_{\forall x} p(x) \log(q(x)) $$

### üîª Algoritmos de optimizaci√≥n

- Gradiente descendiente: Calcula c√≥mo deben ser alterados los pesos para que la funci√≥n de coste pueda alcanzar un m√≠nimo, la desventaja es que este c√°lculo se aplica sobre todo el dataset, por lo que toma mucho coste computacional y es posible que el gradiente se ubique solo un m√≠nimo local.

- Gradiente descendiente estoc√°stico (SGD): es una variaci√≥n del gradiente descendiente en donde los pesos son modificados en cada lote (`batch`) de informaci√≥n. Presenta la ventaja de tener un coste computacional menor pero a cambio, los par√°metros del modelo pueden tener gran varianza debido a la frecuencia de la actualizaci√≥n de los pesos.  

- Momentum: fue dise√±ado para reducir la varianza en del SGD, al acelerar la convergencia hacia la direcci√≥n relevante y reducir la fluctuaci√≥n en la direcci√≥n irrelevante. 

- Gradiente adaptativo (AdaGrad): sigue el mismo principio que el algoritmo SGD, solo que las actualizaciones de los pesos es independiente uno del otro. Esto implica que cada peso empezar√° a obtener su valor y sucesivamente en alg√∫n momento en el tiempo se encuentra la soluci√≥n global.

- ADAM (AdaGrad+Momentum): incorpora los principios anteriores para acelerar el descenso del gradiente al considerar pasos peque√±os pero directos hacia la direcci√≥n correspondiente al m√≠nimo.

## ‚úÖ Evaluaci√≥n

El algorimo aplicado en cada red neuronal representa un modelo de los datos, para determinar si el modelo logra generalizar su comportamiento se deben considerar:

- 1Ô∏è‚É£ M√©tricas de desempe√±o.
- 2Ô∏è‚É£ Curvas de aprendizaje.


### üîª M√©tricas de desempe√±o

- Para problemas de regresi√≥n: como en estos problemas la variable de salida es de tipo num√©rico, se pueden aplicar las mismas funciones de costo que se han definido anteriormente, es decir, `MAE`, `MSE` o `MAPE`, por mencionar algunos ejemplos. 

- Para problemas de clasifiaci√≥n: en estos casos el modelo arroja un resultado Positivo o Negativo, que luego ser√° evaluado como Verdadero o Falso dependiendo de si la predicci√≥n sea correcta o no. Los posibles resultados de un problema de clasificaci√≥n se etiquetan como: 

  - $VP$: verdaderos positivos, 
  - $VN$: verdaderos negativos, 
  - $FP$: falsos positivos,

  - $FN$: falsos negativos,

  A partir de este conteo se definen las siguientes m√©tricas: 

  - Accuracy: $$ \frac{VP+VN}{VP+VN+FP+FN} $$
  - Precision: $$ \frac{VP}{VP+FP} $$
  - Recall (o sensibilidad): $$ \frac{VP}{VP+FN} $$
  - F1-score: $$ \frac{ 2  \cdot (Recall \cdot Precision)}{(Recall + Precision)}$$

  Las m√©tricas de desempe√±o en las clasificaciones se escogen dependiendo del contexto del problema a resolver.

### üîª Curvas de aprendizaje

A partir de las m√©tricas descritas anteriormente, se construyen las curvas de aprendizaje. En ellas podemos evaluar si el algoritmo logr√≥ generalizar los datos, o por el contrario, necesita a√±adirle complejidad o reducirla. Estas caracter√≠sticas son apreciadas al graficar la m√©trica escogida en funci√≥n del n√∫mero de iteraciones (o √©pocas), donde podemos encontrarnos con los siguientes escenarios: 

- Underfitting (o sub ajuste): cuando el modelo es incapaz de obtener resultados correctos por falta de entrenamiento o de m√°s muestras. Se reconoce visualmente cuando existe altos valores de p√©rdida en el set de entrenamiento y validaci√≥n. 

- Overfitting (o sobre ajuste): cuando el modelo se ajusta solo a los datos de entrenamiento y se vuelve incapaz de reconocer nuevos datos. Es visualmente reconocido cuando existe una separaci√≥n importante entre las p√©rdidas del set de entrenamiento y de validaci√≥n. 

- Optimal fit: cuando el modelo logra captar el comportamiento general de los datos. Se puede identificar al obtener valores de p√©rdidas similares en los datos de entrenamiento y validaci√≥n. 

<p align="center">
  <img width="700" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff80030c0-6072-4d13-a6d7-e148f6c5c39a%2FUntitled.png?table=block&id=4c389bbb-7692-43aa-b4e8-016b1a14d03b&width=2050&userId=5d54f20c-b387-4e7e-b2a5-d88e235ada88&cache=v2">
</p>

La forma general de resolver el problema de underfitting es a√±adiendo complejidad a la red. Esto puede llevarse a cabo al incluir m√°s datos o al aumentar el entrenamiento de la red. Para el problema del overfitting es recomendable reducir la cantidad de variables o a√±adir [t√©cnicas de regularizaci√≥n](https://www.notion.so/mariajosemv/Redes-neuronales-en-Keras-y-ScikitLearn-b8fcf479b0464021bb85d1b2a8863404#150430fc557048d7820017da9ca66ea5), las cuales consisten en en disminuir la complejidad del modelo por medio de una penalizaci√≥n aplicada a sus variables m√°s irrelevantes. 

----

## üìå Notas 

Los proyectos fueron construidos utilizando las librer√≠as [Scikit-Learn](https://scikit-learn.org/) y [Keras](https://keras.io/), ambos considerados frameworks de alto nivel, orientados a la experiencia de usuario y caracterizados por permitir realizar experimentaciones r√°pidas. 

Cada proyecto fue realizado como parte del [Curso de Redes Neuronales en Keras y Scikit-Learn](https://platzi.com/cursos/keras-neural-networks/) de Platzi. Para m√°s informaci√≥n y detalles, te invito a leer mis notas del curso en [Notion](https://www.notion.so/mariajosemv/Redes-neuronales-en-Keras-y-ScikitLearn-b8fcf479b0464021bb85d1b2a8863404). ‚ú®
